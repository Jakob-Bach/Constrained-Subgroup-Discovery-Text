\documentclass{article}

\title{
	Constrained Subgroup Discovery
}
\author{
	Jakob Bach~\orcidlink{0000-0003-0301-2798}\\
	\small Karlsruhe Institute of Technology (KIT), Germany\\
	\small \href{mailto:jakob.bach@student.kit.edu}{jakob.bach@student.kit.edu}
}
\date{} % don't display a date

\usepackage[style=numeric, backend=bibtex]{biblatex}
\usepackage[ruled,linesnumbered,vlined]{algorithm2e} % pseudo-code
\usepackage{amsmath} % mathematical symbols
\usepackage{amssymb} % mathematical symbols
\usepackage{amsthm} % theorems, definitions etc.
\usepackage{booktabs} % nicely formatted tables (with top, mid, and bottom rule)
\usepackage{graphicx} % plots
\usepackage{multirow} % cells spanning multiple rows in tables
\usepackage{orcidlink} % ORCID icon
\usepackage{subcaption} % figures with multiple sub-figures and sub-captions
\usepackage{hyperref} % links and URLs

\addbibresource{references.bib}

\newtheorem{proposition}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}
%
\textbf{Keywords:} subgroup discovery, alternatives, constraints, satisfiability modulo theories, mixed-integer programming, explainability, interpretability, XAI

\section{Introduction}
\label{sec:csd:introduction}

\paragraph{Motivation}

\cite{carvalho2019machine} \cite{molnar2020interpretable}

\paragraph{Problem statement}

\paragraph{Related work}

\paragraph{Contributions}

\paragraph{Experimental results}

\paragraph{Outline}

Section~\ref{sec:csd:fundamentals} introduces notation and fundamentals.
Section~\ref{sec:csd:approach} describes and analyzes constrained subgroup discovery.
Section~\ref{sec:csd:related-work} reviews related work.
Section~\ref{sec:csd:experimental-design} outlines our experimental design, while Section~\ref{sec:csd:evaluation} presents the experimental results.
Section~\ref{sec:csd:conclusion} concludes.
Appendix~\ref{sec:csd:appendix} contains supplementary materials.

\section{Fundamentals}
\label{sec:csd:fundamentals}

In this section, we describe fundamentals for our work.
First, we introduce notation (cf.~Section~\ref{sec:csd:fundamentals:notation}).
Next, we describe the problem of subgroup discovery (cf.~Section~\ref{sec:csd:fundamentals:subgroup-discovery}) and common heuristic search methods to solve this problem (cf.~Section~\ref{sec:csd:fundamentals:heuristics}).
Finally, we propose two baselines for subgroup discovery that we also use in our experiments. (cf.~Section~\ref{sec:csd:fundamentals:baselines}).

\subsection{Notation}
\label{sec:csd:fundamentals:notation}

$X \in \mathbb{R}^{m \times n}$ stands for a dataset in the form of a matrix.
Each row is a data object, and each column is a feature.
$F = \{f_1, \dots, f_n\}$ is the corresponding set of feature names.
We assume that categorical features have already been made numeric, e.g., via one-hot or ordinal encoding.
There are also subgroup-discovery methods that focus on categorical data.
$X_{\cdot{}j} \in \mathbb{R}^m$ denotes the vector representation of the $j$-th feature.
$y \in Y^m$ represents the prediction target with domain $Y$, e.g., $Y=\{0,1\}$ for binary classification or $Y=\mathbb{R}$ for regression.
To harmonize evaluation, we only consider binary-classification datasets, though subgroup discovery also works for regression problems.

In subgroup discovery, one ... (goal, decision variables)
Without loss of generality, we assume that the class with label~`1' is the class of interest, also called \emph{positive} class, which should be captured by subgroups.
The function $Q(...,X,y)$ returns the quality of such a subgroup.
Without loss of generality, we assume that this function should be maximized.

\subsection{Subgroup Discovery}
\label{sec:csd:fundamentals:subgroup-discovery}

\cite{helal2016subgroup} \cite{herrera2011overview} \cite{atzmueller2015subgroup} \cite{ventura2018subgroup} \cite{meeng2021real}

\paragraph{Problem}

subgroup == (hyper)box

introduce (here or in notation) the Iverson bracket [], which turns Boolean expressions into 0/1

\paragraph{Evaluation}

A popular evaluation metric for subgroup quality is Weighted Relative Accuracy (WRAcc)~\cite{lavravc1999rule}:
%
\begin{equation}
	\text{WRACC} = \frac{m_b}{m} \cdot \left( \frac{m_b^+}{m_b} - \frac{m^+}{m} \right)
	\label{eq:csd:wracc}
\end{equation}
%
Besides the total number of data objects~$m$, this metric considers the number of positive data objects~$m^+$, the number of data objects in the box~$m_b$, and the number of positive data objects in the box~$m_b^+$.
In particular, WRAcc is the product of two factors:
$m_b / m$ denotes the relative frequency of subgroup membership, i.e., the generality of the subgroup.
The second factor measures the difference in relative frequency of the positive class between the box and the whole dataset, i.e., the relative accuracy of the subgroup.
If the box contains the same fraction of positive data objects as the whole dataset, WRAcc is zero.
The maximum and minimum of WRAcc depend on the class frequencies.
In particular, the maximum WRAcc equals the product of the relative frequencies of positive and negative data objects in the dataset:
%
\begin{equation}
	\text{WRACC}_{\text{max}} = \frac{m^+}{m} \cdot \left( 1 - \frac{m^+}{m} \right)
	\label{eq:csd:wracc-max}
\end{equation}
%
This maximum is reached if all positive data objects are in the box and all negative data objects are outside, i.e., $m_b^+ = m_b = m^+$.
While the maximum is 0.25 if both classes occur with equal frequency, it becomes smaller the more imbalanced the classes are.
Thus, it makes sense to normalize WRAcc when working with datasets with different relative class frequencies.
One normalization, which we use in our experiments, is a max-normalization to the range $[-1, 1]$~\cite{mathonat2021anytime}:
%
\begin{equation}
	\text{nWRACC} = \frac{\text{WRACC}}{\text{WRACC}_{\text{max}}} = \frac{m_b^+ \cdot m - m^+ \cdot m_b}{m^+ \cdot (m - m^+)}
	\label{eq:csd:wracc-normalized}
\end{equation}
%
Alternatively, one can also min-max normalize the range to~$[0, 1]$~\cite{carmona2018unifying}.

\subsection{Heuristic Search Methods for Subgroup Discovery}
\label{sec:csd:fundamentals:heuristics}

In this section, we discuss three heuristic search methods for subgroup discovery.
All of them are well-established and originate from related work.

\begin{algorithm}[t]
	\DontPrintSemicolon
	\caption{\emph{PRIM} for subgroup discovery.}
	\label{al:csd:prim}
\end{algorithm}

\paragraph{PRIM}

\emph{Patient Rule Induction Method (PRIM)}~\cite{friedman1999bump}

Algorithm~\ref{al:csd:prim}

Parameters: peeling fraction $\alpha$, support threshold $\beta_0$

according to Vadim's Medium blog post, REDS article should say that pasting phase of PRIM has little effect on quality

Idea: in pseudocode, already use function getPermissibleFeatureIdxs(), so that part can be plugged in later (when introducing cardinality constraint) without having to repeat whole algorithm

\begin{algorithm}[t]
	\DontPrintSemicolon
	\caption{\emph{Beam Search} for subgroup discovery.}
	\label{al:csd:beam-search}
\end{algorithm}

\paragraph{Beam search}

Algorithm~\ref{al:csd:beam-search}

Parameter: Beam width $w$

\begin{algorithm}[t]
	\DontPrintSemicolon
	\caption{\emph{Best Interval} for subgroup discovery.}
	\label{al:csd:best-interval}
\end{algorithm}

\paragraph{Best interval}

\emph{Best Interval}~\cite{mampaey2012efficient}

Algorithm~\ref{al:csd:best-interval}

Parameter: Beam width $w$

\subsection{Baselines for Subgroup Discovery}
\label{sec:csd:fundamentals:baselines}

In this section, we propose two baselines for subgroup discovery.
They are conceptually simpler than the heuristic search methods (cf.~Section~\ref{sec:csd:fundamentals:heuristics}) and serve as further reference points in our experiments.
While they are also heuristics in the literal sense, we use the term  \emph{baselines} throughout the rest of the paper to refer to these two methods.

\begin{algorithm}[t]
	\DontPrintSemicolon
	\caption{\emph{MORB} for subgroup discovery.}
	\label{al:csd:morb}
\end{algorithm}

\paragraph{MORB}

Algorithm~\ref{al:csd:morb}

\begin{algorithm}[t]
	\DontPrintSemicolon
	\caption{\emph{Random Search} for subgroup discovery.}
	\label{al:csd:random-search}
\end{algorithm}

\begin{proposition}[Complexity of]
	\label{prop:csd:complexity-unconstrained-perfect-box}
\end{proposition}

\paragraph{Random search}

Algorithm~\ref{al:csd:random-search}
Parameter $n\_iters$

\section{Constrained Subgroup Discovery}
\label{sec:csd:approach}

In this section, we discuss subgroup discovery with constraints.
First, we frame subgroup discovery as an SMT optimization problem (cf.~Section~\ref{sec:csd:approach:smt}).
Second, we give a brief overview of potential constraint types (cf.~Section~\ref{sec:csd:approach:constraint-types}).
Third, we formalize and analyze feature-cardinality constraints (cf.~Section~\ref{sec:csd:approach:cardinality}).
Fourth, we formalize and analyze alternative subgroup descriptions (cf.~Section~\ref{sec:csd:approach:alternatives}).

\subsection{SMT Encoding of Subgroup Discovery}
\label{sec:csd:approach:smt}

To find optimal subgroups exactly, one can encode subgroup discovery as a white-box optimization problem and employ a solver.
Here, we propose a Satisfiability Module Theories (SMT)~\cite{barrett2018satisfiability} encoding, which is straightforward given the problem definition (cf.~Section~\ref{sec:csd:fundamentals:subgroup-discovery}).
SMT generally allows expressions in first-order logic with particular interpretations, e.g., arrays, arithmetic, or bit vectors~\cite{barrett2018satisfiability}.
For our encoding of optimal subgroup discovery, we use linear real arithmetic (LRA).
Complementing this SMT encoding, Appendix~\ref{sec:csd:appendix:further-encodings} describes encodings with mixed-integer programming (MIP) and maximum satisfiability (MaxSAT), which require more decision variables.

The optimization problems consists of an objective function and constraints, which we both describe in the following.

\paragraph{Objective function}

As objective function, we use WRAcc, which should be maximized.
In the formula for WRACC (cf.~Equation~\ref{eq:csd:wracc}), $m$ and $m^+$ are constants, while $m_b$ and $m_b^+$ depend on the decision variables.
The previously provided formula seems to be non-linear in the decision variables since $m_b$ appears in enumerator and denominator.
However, one can reformulate the expression by multiplying its two factors, obtaining the following expression:
%
\begin{equation}
	\text{WRACC} = \frac{m_b^+}{m} - \frac{m_b \cdot m^+}{m^2} = \frac{m_b^+ \cdot m - m_b \cdot m^+}{m^2}
	\label{eq:csd:wracc-rearranged}
\end{equation}
%
In this new expression, the denominators are constant and the factor~$m^+$ in the enumerator is constant as well.
Thus, the whole expression is linear in~$m_b^+$ and~$m_b$.
We define these two quantities as linear expressions from binary decision variables~$b \in \{0, 1\}^m$ that denote \emph{subgroup membership}.
I.e., $b_i$~expresses whether the $i$-th data object is in the subgroup or not:
%
\begin{equation}
	\begin{aligned}
		 m_b &:= \sum_{i=1}^{m} b_i \\
		 m_b^+ &:= \sum_{\substack{i \in \{1, \dots, m\} \\ y_i = 1 }} b_i \\
	\end{aligned}
	\label{eq:csd:constraint-m-as-sum}
\end{equation}
%
Since one know the values of the target variable~$y$ a priori, one only needs to sum over the affected, i.e.. positive, data objects in the expression for~$m_b^+$.
Further, defining $m_b^+$ and~$m_b$ as separate integer variables is optional.
One can also directly insert their expressions into Equation~\ref{eq:csd:wracc-rearranged}.
We choose this formulation in our implementation and therefore wrote $:=$ instead of using a proper propositional operator like $\leftrightarrow$ in Equation~\ref{eq:csd:constraint-m-as-sum}.

The formula for nWRAcc (cf.~Equation~\ref{eq:csd:wracc-normalized}) is linear as well, having the same enumerator as Equation~\ref{eq:csd:wracc-rearranged} and a different constant in the denominator.

\paragraph{Constraints}

The subgroup membership~$b_i$ of a data object depends on the bounds of the subgroup.
Thus, we define real-valued decision variables $\mathit{lb}, \mathit{ub} \in \mathbb{R}^n$ for the latter.
In particular, there is one lower bound and one upper bound for each of the $n$~features.
The upper bounds naturally need to be at least as high as the lower bounds:
%
\begin{equation}
	\forall j \in \{1, \dots, n\}:~ \mathit{lb}_j\leq \mathit{ub}_j
	\label{eq:csd:constraint-bounds-monotonic}
\end{equation}
%
A data object is a member of the subgroup if all its feature values are contained within the bounds:
%
\begin{equation}
	\forall i \in \{1, \dots, m\}:~ b_i\leftrightarrow \bigwedge_{j \in \{1, \dots, n\}} \left( \left( X_{ij} \geq \mathit{lb}_j \right) \land \left( X_{ij} \leq \mathit{ub}_j \right) \right)
	\label{eq:csd:constraint-subgroup-membership}
\end{equation}
%
Instead of defining separate decision variables~$b_i$ and binding them to the bounds with a equivalence constraint, one could also insert the Boolean expression on the right-hand-side into Equation~\ref{eq:csd:constraint-m-as-sum} directly.
In particular, $\mathit{lb}_j$ and $\mathit{ub}_j$ are the only decision variables that are strictly necessary in the optimization problem.
However, for formulating some constraint types on subgroups (cf.~Section~\ref{sec:csd:approach:constraint-types}), it is helpful to be able to refer to~$b_i$.

\paragraph{Complete optimization problem}

Combining all prior definitions of decision variables, constraints, and the objective function, we obtain the following SMT optimization problem:

\begin{equation}
	\begin{aligned}
		\max &\quad & Q_{\text{WRAcc}} &= \frac{m_b^+}{m} - \frac{m_b \cdot m^+}{m^2} \\
		\text{s.t.:} &\quad & m_b &:= \sum_{i=1}^{m} b_i \\
		&\quad & m_b^+ &:= \sum_{\substack{i \in \{1, \dots, m\} \\ y_i = 1 }} b_i \\
		&\quad \forall i \in \{1, \dots, m\} & b_i &\leftrightarrow \bigwedge_{j \in \{1, \dots, n\}} \left( \left( X_{ij} \geq \mathit{lb}_j \right) \land \left( X_{ij} \leq \mathit{ub}_j \right) \right) \\
		&\quad \forall j \in \{1, \dots, n\} & \mathit{lb}_j &\leq \mathit{ub}_j \\
		&\quad & b &\in \{0, 1\}^m \\
		&\quad & \mathit{lb}, \mathit{ub} &\in \mathbb{R}^n
	\end{aligned}
	\label{eq:csd:smt-unconstrained-complete}
\end{equation}

We refer to this optimization problem as \emph{unconstrained subgroup discovery} in the following since it only contains constraints that are technically necessary to define subgroup discovery properly but no additional user constraints.

\subsection{Overview of Constraint Types}
\label{sec:csd:approach:constraint-types}

domain-knowledge
secondary objectives
regularization
alternatives (covering different data objects and covering same data objects differently)

existing methods need adaptation to support certain constraint types, white-box formulation like SMT is more general

\subsection{Feature-Cardinality Constraints}
\label{sec:csd:approach:cardinality}

In this section, we discuss feature-cardinality constraints for subgroup discovery.
First, we motivate and formalize them (cf.~Section~\ref{sec:csd:approach:cardinality:concept}).
Next, we describe how to integrate them into our SMT encoding of subgroup discovery (cf.~Section~\ref{sec:csd:approach:cardinality:smt}), heuristic search methods (cf.~Section~\ref{sec:csd:approach:cardinality:heuristics}), and baselines (cf.~Section~\ref{sec:csd:approach:cardinality:baselines}).
Finally, we analyze the computational complexity of subgroup discovery with this constraint type (cf.~Section~\ref{sec:csd:approach:cardinality:complexity}).

\subsubsection{Concept}
\label{sec:csd:approach:cardinality:concept}

define term selected == restricted

note that only constraints added, rest of optimization problem (particularly objective) remains as-is

give reason why less than $k$ features may be selected

\subsubsection{SMT Encoding}
\label{sec:csd:approach:cardinality:smt}

We first need to define whether a feature is selected or not.
Thus, we introduce binary decision variables $s_j, s_j^{\text{lb}}, s_j^{\text{ub}} \in \{0, 1\}^n$.
A feature is selected if its bounds exclude at least one data object from the subgroup, i.e., the lower bound is higher than the minimum feature value or the upper bound is lower than the maximum feature value:
%
\begin{equation}
	\begin{aligned}
		s_j^{\text{lb}} &\leftrightarrow \left( \textit{lb}_j > \min_{i \in \{1, \dots, m\}} X_{ij} \right) \\
		s_j^{\text{ub}} &\leftrightarrow \left( \textit{ub}_j < \max_{i \in \{1, \dots, m\}} X_{ij} \right) \\
		s_j &\leftrightarrow \left( s_j^{\text{lb}} \lor s_j^{\text{ub}} \right) \\
		j &\in \{1, \dots, n\}
	\end{aligned}
	\label{eq:csd:constraint-feature-selection}
\end{equation}
%
Given the definition of~$s_j$, setting an upper bound on the number of selected features is straightforward:
%
\begin{equation}
	\sum_{j=1}^n s_j \leq k
	\label{eq:csd:constraint-cardinality}
\end{equation}
%
Instead of defining decision variables $s_j$, $s_j^{\text{lb}}$, and $s_j^{\text{ub}}$, one could also insert the corresponding expressions into Equation~\ref{eq:csd:constraint-cardinality} directly.
However, we will use~$s_j$ for alternative subgroup descriptions (cf.~Section~\ref{sec:csd:approach:alternatives:smt}) as well.

The overall optimization problem of subgroup discovery with feature-cardinality constraints is the one of unconstrained subgroup discovery (cf.~Equation~\ref{eq:csd:smt-unconstrained-complete}) supplemented by the variables and constraints from Equations~\ref{eq:csd:constraint-feature-selection} and~\ref{eq:csd:constraint-cardinality}.

\subsubsection{Integration into Heuristic Search Methods}
\label{sec:csd:approach:cardinality:heuristics}

maybe mention antimonotonicity (see definition below)

\subsubsection{Integration into Baselines}
\label{sec:csd:approach:cardinality:baselines}

\subsubsection{Computational Complexity}
\label{sec:csd:approach:cardinality:complexity}

\paragraph{Hardness}

(cf.~Appendix~\ref{sec:csd:appendix:proofs:cardinality} for the proof)

\begin{proposition}[Complexity of]
	\label{prop:csd:complexity-cardinality-perfect-box}
\end{proposition}

(cf.~Appendix~\ref{sec:csd:appendix:proofs:cardinality} for the proof)

\begin{proposition}[Complexity of]
	\label{prop:csd:complexity-cardinality-imperfect-box}
\end{proposition}

\paragraph{Parameterized complexity}

\begin{proposition}[Parameterized complexity of]
	\label{prop:csd:complexity-unconstrained-xp}
\end{proposition}

\begin{proposition}[Parameterized complexity of]
	\label{prop:csd:complexity-cardinality-xp}
\end{proposition}

\subsection{Alternative Subgroup Descriptions}
\label{sec:csd:approach:alternatives}

In this section, we propose the optimization problem of alternative subgroup descriptions.
First, we motivate and formalize the problem (cf.~Section~\ref{sec:csd:approach:alternatives:concept}).
Next, we describe how to phrase it within our SMT encoding of subgroup discovery (cf.~Section~\ref{sec:csd:approach:alternatives:smt}) and heuristic search methods (cf.~Section~\ref{sec:csd:approach:alternatives:heuristics}).
Finally, we analyze the computational complexity of this problem (cf.~Section~\ref{sec:csd:approach:alternatives:complexity}).

\subsubsection{Concept}
\label{sec:csd:approach:alternatives:concept}

For alternative subgroup descriptions, we assume to have an \emph{original subgroup} given, with subgroup membership~$b^{(0)} \in \{0, 1\}^m$ of data objects and with feature selection~$s^{(0)} \in \{0, 1\}^n$.
When searching alternatives, we do not optimize subgroup quality but the similarity to the original subgroup. 
We express this similarity in terms of subgroup membership.
Also, we introduce constraints to ensure that the new subgroup descriptions are alternative enough.
We express this dissimilarity in terms of the subgroups' feature selection.
Thus, we recommend to employ a feature-cardinality constraint as well.
In a nutshell, alternative subgroup descriptions should produce similar predictions as the original subgroup but use different features.

\paragraph{Objective function}

There are various options to quantify the similarity between subgroup-membership vectors.
For example, the Hamming distance counts how many vector entries differ~\cite{choi2010survey}.
We turn this distance into a similarity measure by counting identical vector entries.
Further, we normalize the similarity with the vector length, i.e., number of data objects~$m$, to obtain the following \emph{normalized Hamming similarity} for two subgroup-membership vectors~$b', b'' \in \{0, 1\}^m$:
%
\begin{equation}
	\text{sim}_{\text{nHamm}}(b', b'') = \frac{\sum_{i=1}^{m} [b'_i = b''_i]}{m}
	\label{eq:csd:hamming-general}
\end{equation}
%
If either $b'$ or $b''$ is constant, then this similarity measure is linear in its remaining argument.
Further, if one considers one vector to be a prediction and the other one to be the ground truth, Equation~\ref{eq:csd:hamming-general} equals prediction accuracy.

Another popular similarity measure for sets or binary vectors is the Jaccard index~\cite{choi2010survey}, which relates the overlap of positive vector entries to their union:
%
\begin{equation}
	\text{sim}_{\text{Jacc}}(b', b'') = \frac{\sum_{i=1}^{m} [b'_i \land b''_i ]}{\sum_{i=1}^{m} [b'_i \lor b''_i]}
	\label{eq:csd:jaccard}
\end{equation}
%
However, this similarity measure is not linear in~$b'$ and~$b''$, which prevents its use in certain white-box solvers.
Thus, we use the normalized Hamming similarity as the objective function.

\paragraph{Constraints}

Given the original subgroup, we search for alternative subgroup descriptions sequentially, with one alternative per iteration.
Let $a \in \mathbb{N}$ denote the number of alternatives and $\tau \in \mathbb{R}_{\geq 0}$ be a dissimilarity threshold.
We require each new, $a$-th subgroup description to have a sufficiently different feature selection compared to all {existing subgroups}, including the original one:
%
\begin{equation}
	\forall l \in \{0, \dots, a-1\}:~ \text{dis}(s^{(a)}, s^{(l)}) \geq \tau
	\label{eq:csd:constraint-dissimilarity-general}
\end{equation}
%
Again, there are various options to quantify the dissimilarity~$\text{dis}(\cdot)$ between feature-selection vectors.
We employ the following \emph{deselection dissimilarity} in combination with an adapted dissimilarity threshold:
%
\begin{equation}
	\text{dis}_{\text{des}}(s^{\text{new}}, s^{\text{old}}) = \sum_{j=1}^n [\lnot s^{\text{new}}_j \land s^{\text{old}}_j] \geq \min \left( \tau_{\text{abs}},~\sum_{j=1}^n s^{\text{old}}_j \right)
	\label{eq:csd:constraint-dissimilarity-special}
\end{equation}
%
This dissimilarity counts how many of the previously selected features are \emph{not} selected in the new subgroup description.
These features may either be replaced by other features or the total number of selected features may be reduced.
The constraints ensures that at least $\tau_{\text{abs}} \in \mathbb{N}$ features are deselected but never more than there were selected before, which would be infeasible.
For maximum dissimilarity, none of the previously selected features may be selected again.
Note that the dissimilarity measure is asymmetric, i.e., $\text{dis}_{\text{des}}(s^{\text{new}}, s^{\text{old}}) \neq \text{dis}_{\text{des}}(s^{\text{old}}, s^{\text{new}})$.
While this property would be an issue in a simultaneous search for multiple alternatives, i.e., without clear ordering, it is acceptable for sequential search, where `old' and `new' are well-defined.

Conceptually, one could also employ a more common dissimilarity measure like the Jaccard distance or the Dice dissimilarity~\cite{choi2010survey}.
The latter two are even symmetric and normalized to~$[0,1]$.
However, our deselection dissimilarity has two advantages:
First, if $s^{\text{old}}$ is constant, the dissimilarity is \emph{linear} in $s^{\text{new}}$, as it amounts to a simple sum, even if the exact number of newly selected features is unknown yet.
This property is useful in solver-based search (cf.~Section~\ref{sec:csd:approach:alternatives:smt}).
In contrast, Jaccard distance and Dice dissimilarity involve a fraction and are therefore non-linear.
Second, the constraint from Equation~\ref{eq:csd:constraint-dissimilarity-special} is \emph{antimonotonic} in the new feature selection:
If a feature set satisfies the constraint, all its subsets also satisfy the constraint.
Vice versa, if a feature set violates the constraint, all its supersets also violate the constraint.
This property is useful in heuristic search (cf.~Section~\ref{sec:csd:approach:alternatives:heuristics}).
Using the Jaccard distance or Dice dissimilarity in the constraint may violate the property.
In particular, these dissimilarities can increase by selecting features that were not selected in the existing subgroup.

\subsubsection{SMT Encoding}
\label{sec:csd:approach:alternatives:smt}

We only need to slightly reformulate Equation~\ref{eq:csd:hamming-general} to obtain an objective function that is linear regarding the alternative subgroup-membership vector~$b^{(a)}$:
%
\begin{equation}
	\text{sim}_{\text{nHamm}}(b^{(a)}, b^{(0)}) = \frac{\sum_{i=1}^m \left( b_i^{(a)} \leftrightarrow b_i^{(0)} \right) }{m} = \frac{\sum\limits_{\substack{i \in \{1, \dots, m\} \\ b_i^{(0)} = 1}} b_j^{(a)} + \sum\limits_{\substack{i \in \{1, \dots, m\} \\ b_i^{(0)} = 0}} \lnot b_j^{(a)}}{m}
	\label{eq:csd:hamming-smt}
\end{equation}
%
In particular, since $b^{(0)}$~is known and therefore constant, we employ the expression on the right-hand side, i.e., do not need the logical equivalence operator.
Instead, we compute two sums, one for data objects that are members of the original subgroup and one for non-members.

To formulate the dissimilarity constraints, we leverage that the feature-selection vector~$s^{(l)}$ is known for all existing subgroups as well.
Thus, we adapt Equation~\ref{eq:csd:constraint-dissimilarity-special} as follows:
%
\begin{equation}
	\forall l \in \{0, \dots, a-1\}:~ \text{dis}_{\text{des}}(s^{(a)}, s^{(l)}) = \sum_{\substack{j \in \{1, \dots, n\} \\ s^{(l)}_j = 1}} \lnot s^{(a)}_j \geq \min \left( \tau_{\text{abs}},~\sum_{j=1}^n s^{(l)}_j \right)
	\label{eq:csd:constraint-dissimilarity-smt}
\end{equation}
%
In particular, we only sum over features that were selected in the existing subgroup and check whether they are deselected.
To tie the variable~$s^{(a)}$ to the subgroup's bounds, we use Equation~\ref{eq:csd:constraint-feature-selection}, which we already employed for feature cardinality constraints.

\subsubsection{Integration into Heuristic Search Methods}
\label{sec:csd:approach:alternatives:heuristics}

Beam only, no baselines.
Explain antimonotonic, state that SMT is more flexible

\subsubsection{Computational Complexity}
\label{sec:csd:approach:alternatives:complexity}

\paragraph{Hardness}

(cf.~Appendix~\ref{sec:csd:appendix:proofs:alternatives} for the proof)

\begin{proposition}[Complexity of]
	\label{prop:csd:complexity-alternatives-perfect-box}
\end{proposition}

(cf.~Appendix~\ref{sec:csd:appendix:proofs:alternatives} for the proof)

\begin{proposition}[Complexity of]
	\label{prop:csd:complexity-alternatives-imperfect-box}
\end{proposition}

\paragraph{Parameterized complexity}

\begin{proposition}[Parameterized complexity of]
	\label{prop:csd:complexity-alternatives-xp}
\end{proposition}

\section{Related Work}
\label{sec:csd:related-work}

In this section, we review related work.
Next to literature on subgroup discovery (cf.~Section~\ref{sec:csd:related-work:subgroup-discovery}), we also discuss relevant work from the adjacent field of feature selection (cf.~Section~\ref{sec:csd:related-work:feature-selection}) and other related areas (cf.~Section~\ref{sec:csd:related-work:other}).

\subsection{Subgroup Discovery}
\label{sec:csd:related-work:subgroup-discovery}

PRIM~\cite{friedman1999bump}, BI~\cite{mampaey2012efficient}
depth-first~\cite{millot2020optimal}
exhaustive~\cite{atzmueller2006sd, atzmueller2009fast, grosskreutz2009subgroup, lemmerich2016fast}
exhaustive with diversity~\cite{bosc2018anytime, lemmerich2010fast}
heuristics with diversity \cite{leeuwen2012diverse, lucas2018ssdp+, proencca2022robust}
analyze Pareto front for diversity (exact and greedy) \cite{leeuwen2013discovering}
diverse subgroup lists \cite{lopez2023discovering, lopez2023novel}
diverse rule sets \cite{zhang2020diverse}
heuristic with constraints \cite{lavravc2006relevancy}
contrasting SD \cite{langohr2013contrasting}
involve domain experts/knowledge \cite{dzyuba2013interactive, gamberger2002expert, lemmerich2011local}
background knowledge \cite{atzmueller2005exploiting, atzmueller2006methodological}
`propositionalization to describe subgroups' \cite{zelezny2006propositionalization}

from chair: \cite{arzamasov2021reds} \cite{arzamasov2022pedagogical} \cite{vollmer2019informative}

minimizing subgroups NP-hard~\cite{boley2009non}

measures of subgroup complexity \cite{helal2016subgroup, herrera2011overview, ventura2018subgroup} -> num subgroups and num selected features

\subsection{Feature Selection}
\label{sec:csd:related-work:feature-selection}

\cite{bach2022empirical} \cite{bach2023finding}

\subsection{Other Fields}
\label{sec:csd:related-work:other}

\cite{bailey2014alternative} \cite{grossi2017survey}
\cite{guidotti2022counterfactual}
\cite{narodytska2018learning} \cite{schidler2021sat} \cite{yu2021learning}

\section{Experimental Design}
\label{sec:csd:experimental-design}

In this section, we introduce our experimental design.
After a brief overview of its components (cf.~Section~\ref{sec:csd:experimental-design:overview}), we describe evaluation metrics (cf.~Section~\ref{sec:csd:experimental-design:metrics}), subgroup-discovery methods (cf.~Section~\ref{sec:csd:experimental-design:methods}), experimental scenarios (cf.~Section~\ref{sec:csd:experimental-design:scenarios}), and datasets (cf.~Section~\ref{sec:csd:experimental-design:datasets}).
Finally, we shortly outline our implementation (cf.~Section~\ref{sec:csd:experimental-design:implementation}).

\subsection{Overview}
\label{sec:csd:experimental-design:overview}

In our experiments, we evaluate six subgroup-discovery methods on 27 binary-classification datasets.
We measure the subgroup quality in terms of nWRAcc and also record the runtime of the methods.
We analyze four \emph{experimental scenarios}:
First, we compare all subgroup-discovery methods without constraints.
Second, we vary the timeout in solver-based search.
Third, we compare all subgroup-discovery methods with a constraint on the number of selected features~$k$, varying the latter parameter.
Fourth, we search for alternative subgroup descriptions with one solver-based and one heuristic search method.
We vary the number of alternatives~$a$ and the dissimilarity threshold~$\tau_{\text{abs}}$.

\subsection{Evaluation Metrics}
\label{sec:csd:experimental-design:metrics}

\paragraph{Subgroup quality}

We use \emph{nWRAcc} (cf.~Equation~\ref{eq:csd:wracc-normalized}) to quantify subgroup quality.
To analyze how well the subgroup-discovery methods generalize, we conduct a stratified five-fold cross-validation.
In particular, each run of a subgroup-discovery method only uses 80\% of the data objects of a dataset as training data, while the remaining data objects serve as test data.
Based on the bounds of each found subgroup, we determine subgroup membership for data objects from training \emph{and} test data.
Based on this membership information and the true class labels~$y$, we compute \emph{training-set nWRAcc} and \emph{test-set nWRAcc} on the corresponding part of the data separately.

\paragraph{Subgroup similarity}

For evaluating alternative subgroup descriptions, we not only consider their quality but also their similarity to the original subgroup.
To this end, we use \emph{normalized Hamming similarity} (cf.~Equation~\ref{eq:csd:hamming-general}) and \emph{Jaccard similarity} (cf.~Equation~\ref{eq:csd:jaccard}) to compare subgroup membership of data objects between the original subgroup and an alternative subgroup description.

\paragraph{Runtime}

As \emph{runtime}, we consider the training time of the subgroup-discovery methods.
In particular, we measure how long the search for each subgroup takes.
In solver-based search for subgroups, we also register whether the solver timed or not.
In the latter case, the found solution is optimal, at least on the training set; in the former case, it may be suboptimal.

\subsection{Subgroup-Discovery Methods}
\label{sec:csd:experimental-design:methods}

We employ six subgroup-discovery methods:
Our solver-based one (cf.~Section~\ref{sec:csd:approach:smt}), three heuristic search methods from related work (cf.~Section~\ref{sec:csd:fundamentals:heuristics}), and our two baselines (cf.~Section~\ref{sec:csd:fundamentals:baselines}).

\paragraph{Solver-based search}

For solver-based search, we use an SMT optimizer to solve our \emph{SMT} encoding of subgroup discovery (cf.~Equation~\ref{eq:csd:smt-unconstrained-complete}).
Unlike the other five subgroup-discovery methods in our experiments, this method is theoretically guaranteed to find the exact global optimum, though only if it is granted sufficient time.
In practice, however, we set solver timeouts to keep the runtime under control (cf.~Section~\ref{sec:csd:experimental-design:scenarios}).

\paragraph{Heuristic search}

We evaluate three heuristic search methods from related work:
\emph{PRIM} (cf.~Algorithm~\ref{al:csd:prim}), \emph{Beam Search} (cf.~Algorithm~\ref{al:csd:beam-search}, subsequently called \emph{Beam}), and \emph{Best Interval} (cf.~Algorithm~\ref{al:csd:best-interval}, subsequently called \emph{BI}).
We set the peeling fraction of PRIM to~$\alpha = 0.05$, consistent with other implementations of PRIM~\cite{arzamasov2021reds, kwakkel2017the}, and the support threshold to~$\beta_0 = 0$, so the shrinking of the box is solely limited by WRAcc improvement and not the box size.
For \emph{Beam} and \emph{BI}, we choose a beam width of $w=10$, falling between default values used in other implementations~\cite{arzamasov2021reds, lemmerich2019pysubgroup}.

\paragraph{Baselines}

We also include baselines, which are even simpler than the heuristic search methods.
In particular, we employ our own methods \emph{MORB} (cf.~Algorithm~\ref{al:csd:morb}) and \emph{Random Search} (cf.~Algorithm~\ref{al:csd:random-search}, subsequently called \emph{Random}).
\emph{MORB} is parameter-free.
\emph{Random} has one hyperparameter, i.e., the number of iterations, which we set to~$n\_iters = 1000$.

\subsection{Experimental Scenarios}
\label{sec:csd:experimental-design:scenarios}

We evaluate the subgroup-discovery methods in four experimental scenarios.
Two of the scenarios do not involve all subgroup-discovery methods.

\paragraph{Unconstrained subgroup discovery}

Our first experimental scenario (cf. Section~\ref{sec:csd:evaluation:unconstrained} for results) compares all six subgroup-discovery methods without any constraints.
This comparison allows us to assess the effectiveness of the solver-based search method \emph{SMT} for `conventional' subgroup discovery and serves as a reference point for subsequent experiment with constraints.

\paragraph{Solver timeouts}

Our second experimental scenario (cf.~Section~\ref{sec:csd:evaluation:timeouts} for results) takes a deeper dive into \emph{SMT} as subgroup-discovery method.
In particular, we analyze whether setting solver timeouts enables finding solutions with reasonable quality in a shorter time frame.
If the solver does not finish within a given timeout, we record the currently best solution at this time, which may be suboptimal.
We evaluate twelve exponentially scaled timeout values, i.e., \{1~s, 2~s, 4~s, $\dots$, 2048~s\}.
In the three other experimental scenarios, we employ the maximum timeout of 2048~s for \emph{SMT}.
Since the heuristic search methods and baselines are significantly faster, we do not conduct a timeout analysis for them.

\paragraph{Feature-cardinality constraints}

Our third experimental scenario (cf.~Section~\ref{sec:csd:evaluation:cardinality} for results) analyzes feature-cardinality constraints (cf.~Section~\ref{sec:csd:approach:cardinality}) for all six subgroup-discovery methods.
In particular, we evaluate $k \in \{1, 2, 3, 4, 5\}$ selected features.
These values of~$k$ are upper bounds (cf.~Equation~\ref{eq:csd:constraint-cardinality}), i.e., the subgroup-discovery methods may select less features if selecting more does not improve subgroup quality.

\paragraph{Alternative subgroup descriptions}

Our fourth experimental scenario (cf. Section~\ref{sec:csd:evaluation:alternatives} for results) studies alternative subgroup descriptions (cf.~Section~\ref{sec:csd:approach:alternatives}) for \emph{SMT} and \emph{Beam}, i.e., one solver-based and one heuristic search method.
We limit the number of selected features to~$k=3$, which yields reasonably high subgroup quality (cf.~Section~\ref{sec:csd:evaluation:cardinality}).
We search for $a=5$ alternative subgroup descriptions with a dissimilarity threshold $\tau_{\text{abs}} \in \{1, 2, 3\}$.
Since each dataset has $n \geq 20$ features (cf.~Section~\ref{sec:csd:experimental-design:datasets}), our choices of~$a$, $k$, and~$\tau$ ensure that there always is a valid alternative.

\begin{table}[p]
	\centering
	\begin{tabular}{lrrll}
		\toprule
		\multirow{2}{*}{Dataset} & \multirow{2}{*}{$m$} & \multirow{2}{*}{$n$} & \multicolumn{2}{c}{Timeouts} \\
		\cmidrule(lr){4-5}
		& & & Max~$k$ & Any~$k$ \\
		\midrule
		backache & 180 & 32 & No & No \\
		chess & 3196 & 36 & No & No \\
		churn & 5000 & 20 & Yes & Yes \\
		clean1 & 476 & 168 & No & No \\
		clean2 & 6598 & 168 & No & No \\
		coil2000 & 9822 & 85 & Yes & Yes \\
		credit\_g & 1000 & 20 & Yes & Yes \\
		dis & 3772 & 29 & No & No \\
		GE\_2\_Way\_20atts\_0.1H\_EDM\_1\_1 & 1600 & 20 & Yes & Yes \\
		GE\_2\_Way\_20atts\_0.4H\_EDM\_1\_1 & 1600 & 20 & No & No \\
		GE\_3\_Way\_20atts\_0.2H\_EDM\_1\_1 & 1600 & 20 & Yes & Yes \\
		GH\_20atts\_1600\_Het\_0.4\_0.2\_50\_EDM\_2\_001 & 1600 & 20 & Yes & Yes \\
		GH\_20atts\_1600\_Het\_0.4\_0.2\_75\_EDM\_2\_001 & 1600 & 20 & Yes & Yes \\
		Hill\_Valley\_with\_noise & 1212 & 100 & Yes & Yes \\
		horse\_colic & 368 & 22 & No & No \\
		hypothyroid & 3163 & 25 & No & No \\
		ionosphere & 351 & 34 & Yes & Yes \\
		molecular\_biology\_promoters & 106 & 57 & No & No \\
		mushroom & 8124 & 22 & No & No \\
		ring & 7400 & 20 & Yes & Yes \\
		sonar & 208 & 60 & No & Yes \\
		spambase & 4601 & 57 & No & Yes \\
		spect & 267 & 22 & No & No \\
		spectf & 349 & 44 & No & Yes \\
		tokyo1 & 959 & 44 & No & Yes \\
		twonorm & 7400 & 20 & Yes & Yes \\
		wdbc & 569 & 30 & No & No \\
		\bottomrule
	\end{tabular}
	\caption{
		Datasets from PMLB used in our experiments.
		$m$~denotes the number of data objects and $n$~the number of features.
		In dataset names, we replaced \emph{GAMETES\_Epistasis} with  \emph{GE\_} and \emph{GAMETES\_Heterogeneity} with \emph{GH\_} to reduce the table's width.
		The column \emph{Timeouts} indicates whether at least one timeout occurred with \emph{SMT} as the subgroup-discovery method and the highest timeout (2048~s), optimizing the original subgroup without cardinality constraints (\emph{Max~$k$}) or in any cardinality setting (\emph{Any~$k$}).
	}
	\label{tab:csd:datasets}
\end{table}

\subsection{Datasets}
\label{sec:csd:experimental-design:datasets}

We use binary-classification datasets from the Penn Machine Learning Benchmarks (PMLB)~\cite{olson2017pmlb, romano2021pmlb}.
If both classes occur with different frequencies, we encode the minority class as the class of interest, i.e., assign~1 as it class label.
To avoid prediction scenarios that may be too easy or have not enough features for alternative subgroup descriptions, we only select datasets with at least 100 data objects and 20 features.
Next, we exclude one dataset with 1000 features, which has a significantly higher dimensionality than all remaining datasets.
Finally, we manually exclude datasets that seem duplicated or modified versions of other datasets in our experiments.

Based on these criteria, we obtain 27 datasets with 106 to 9822 data objects and 20 to 168 features (cf.~Table~\ref{tab:csd:datasets}).
The datasets do not contain any missing values.
Further, there are no categorical feature values since PMLB encodes them ordinally by default.

\subsection{Implementation and Execution}
\label{sec:csd:experimental-design:implementation}

We implemented all subgroup-discovery methods, experiments, and evaluations in Python~3.8.
A requirements file in our repository specifies the versions of all Python packages.
The solver \emph{Z3}~\cite{bjorner2015nuz, deMoura2008z3} carries out the SMT optimization.
The experimental pipeline parallelizes over datasets, cross-validation folds, and subgroup-discovery methods, while each of these experimental tasks runs single-threaded.
We ran the pipeline on a server with 128~GB RAM and an \emph{AMD EPYC 7551} CPU, having 32~physical cores and a base clock of 2.0~GHz.
With this hardware, the parallelized pipeline run took approximately 39~hours.

\section{Evaluation}
\label{sec:csd:evaluation}

In this section, we evaluate our experiments.
In particular, we cove our four experimental scenarios, i.e., unconstrained subgroup discovery (cf.~Section~\ref{sec:csd:evaluation:unconstrained}), solver timeouts (cf.~Section~\ref{sec:csd:evaluation:timeouts}), feature-cardinality constraints (cf.~Section~\ref{sec:csd:evaluation:cardinality}), and alternative subgroup descriptions. (cf.~Section~\ref{sec:csd:evaluation:alternatives}).
Finally, we summarize key experimental results (cf.~Section~\ref{sec:csd:evaluation:summary}).

\subsection{Unconstrained Subgroup Discovery}
\label{sec:csd:evaluation:unconstrained}

\paragraph{Training-set quality}

\paragraph{Test-set quality}

\paragraph{Overfitting}

\paragraph{Runtime}

\subsection{Solver Timeouts}
\label{sec:csd:evaluation:timeouts}

\subsection{Feature-Cardinality Constraints}
\label{sec:csd:evaluation:cardinality}

\paragraph{Quality}

\paragraph{Runtime}

\subsection{Alternative Subgroup Descriptions}
\label{sec:csd:evaluation:alternatives}

\paragraph{Quality}

\paragraph{Runtime}

\subsection{Summary}
\label{sec:csd:evaluation:summary}

\paragraph{Unconstrained subgroup discovery (cf.~Section~\ref{sec:csd:evaluation:unconstrained})}

\paragraph{Solver timeouts (cf.~Section~\ref{sec:csd:evaluation:timeouts})}

\paragraph{Feature-cardinality constraints (cf.~Section~\ref{sec:csd:evaluation:cardinality})}

\paragraph{Alternative subgroup descriptions (cf.~Section~\ref{sec:csd:evaluation:alternatives})}

\section{Conclusions and Future Work}
\label{sec:csd:conclusion}

In this section, we recap our article (cf.~Section~\ref{sec:csd:conclusion:conclusion}) and propose directions for future work (cf.~Section~\ref{sec:csd:conclusion:future-work}).

\subsection{Conclusions}
\label{sec:csd:conclusion:conclusion}

\subsection{Future Work}
\label{sec:csd:conclusion:future-work}

\paragraph{Datasets}

Our evaluation used over two dozen generic benchmark datasets (cf.~Section~\ref{sec:csd:experimental-design:datasets}).
While such an evaluation shows general trends, the impact of constraints naturally depends on the dataset.
Thus, our results may not transfer to each particular scenario.
This caveat calls for domain-specific case studies.
In such studies, one could also interpret alternative subgroup descriptions qualitatively, i.e., from the domain perspective.

\paragraph{Constraint types}

We formalized, analyzed, and evaluated two constraint types, i.e., feature-cardinality constraints (cf.~Sections~\ref{sec:csd:approach:cardinality} and~\ref{sec:csd:evaluation:cardinality}) and alternative subgroup descriptions (cf.~Sections~\ref{sec:csd:approach:alternatives} and~\ref{sec:csd:evaluation:alternatives}).
As mentioned in Section~\ref{sec:csd:approach:constraint-types}, there are further constraint types one could investigate, e.g., domain-specific constraints, secondary objectives, or alternatives in the sense of covering different data objects rather than covering the same data objects differently.

For our constraint type for alternative subgroup descriptions, one could analyze other dissimilarities, e.g., symmetric ones rather than the asymmetric one we used (cf.~Equation~\ref{eq:csd:constraint-dissimilarity-general}).
While the SMT encoding of subgroup discovery is relatively flexible regarding dissimilarities, integrating them into heuristic search methods may be challenging, e.g., if they are not antimonotonic.

\paragraph{Formalization}

In solver-based search for subgroups, we used an SMT encoding (cf.~Section~\ref{sec:csd:approach:smt}) and one particular solver.
Different white-box encodings or solvers may speed up the search and lead to less timeouts, potentially improving the subgroup quality.
We already proposed MIP and MaxSAT encodings of subgroup discovery (cf.~Appendix~\ref{sec:csd:appendix:further-encodings}), though without evaluation.

Two assumptions for subgroup discovery in our paper were numerical features and a binary target (cf.~Section~\ref{sec:csd:fundamentals:notation}).
One could adapt the SMT encoding to multi-valued categorical features and continuous targets.

\paragraph{Computational complexity}

We established $\mathcal{NP}$-hardness for optimizing perfect and imperfect subgroups with feature-cardinality constraints (cf.~Propositions~\ref{prop:csd:complexity-cardinality-perfect-box} and~\ref{prop:csd:complexity-cardinality-imperfect-box}).
While the problem admits a polynomial-time algorithm for perfect subgroups without such constraints (cf.~Proposition~\ref{prop:csd:complexity-unconstrained-perfect-box}), we did not analyze the general unconstrained problem, i.e., including imperfect subgroups.

Further, we showed $\mathcal{NP}$-hardness for finding alternative subgroup descriptions for perfect and imperfect subgroups (cf.~Propositions~\ref{prop:csd:complexity-alternatives-perfect-box} and~\ref{prop:csd:complexity-alternatives-imperfect-box}).
In both cases, our proofs tackle the decision problem whether perfect alternatives exist, i.e., alternative descriptions that entail exactly the same subgroup membership of data objects as the original subgroup.
One could try to extend these proofs to imperfect alternatives, or generally speaking, optimizing alternatives.

Regarding parameterized complexity for the unconstrained scenario, feature-cardinality constraints, and alternative subgroup descriptions, we proved membership in the relatively broad complexity class $\mathcal{XP}$ (cf.~Propositions~~\ref{prop:csd:complexity-unconstrained-xp}, \ref{prop:csd:complexity-cardinality-xp}, and~\ref{prop:csd:complexity-alternatives-xp}).
One may attempt to tighten these results.

Finally, while we described how one can integrate feature-cardinality constraints and alternative subgroup descriptions into heuristic search methods (cf.~Sections~\ref{sec:csd:approach:cardinality:heuristics} and~\ref{sec:csd:approach:alternatives:heuristics}), we did not provide quality guarantees relative to the exact optimum.
In that regard, one could seek for an approximation complexity result, e.g., membership in the complexity class~$\mathcal{APX}$.

%~\\
%\noindent \textsc{Acknowledgments}\quad
%This work was supported by the Ministry of Science, Research and the Arts Baden-Württemberg, project \emph{Algorithm Engineering for the Scalability Challenge (AESC)}.

\appendix

\section{Appendix}
\label{sec:csd:appendix}

In this section, we provide supplementary materials.
Appendix~\ref{sec:csd:appendix:further-encodings} describes further encodings of the subgroup-discovery problem, complementing the SMT encoding from Section~\ref{sec:csd:approach:smt}.
Appendix~\ref{sec:csd:appendix:proofs} contains proofs for propositions from Section~\ref{sec:csd:approach}.

\subsection{Further Problem Encodings of Subgroup Discovery}
\label{sec:csd:appendix:further-encodings}

\cite{mosek2022modeling}
\cite{sinz2005towards}
\cite{ulrich2022selecting}

\paragraph{MIP}

Our published code contains a MIP implementation with the package \emph{OR-Tools}~\cite{perron2022or-tools}, using \emph{SCIP}~\cite{bestuzheva2021scip} as the optimizer.
However, this implementation was (on average) slower than the SMT implementation in preliminary experiments, so we stuck to the latter for our main experiments (cf.~Section~\ref{sec:csd:experimental-design:methods}).

\paragraph{MaxSAT}

\cite{li2021maxsat} \cite{bacchus2021maximum}

\subsection{Proofs}
\label{sec:csd:appendix:proofs}

In this section, we provide proofs for propositions from Section~\ref{sec:csd:approach}.
Section~\ref{sec:csd:appendix:proofs:cardinality} proves complexity results for subgroup discovery with feature-cardinality constraints, while Section~\ref{sec:csd:appendix:proofs:alternatives} proves complexity results for searching alternative subgroup descriptions.

\subsubsection{Feature-Cardinality Constraints}
\label{sec:csd:appendix:proofs:cardinality}

\paragraph{Proof of Proposition~\ref{prop:csd:complexity-cardinality-perfect-box}}
%
\begin{proof}
\end{proof}

\paragraph{Proof of Proposition~\ref{prop:csd:complexity-cardinality-imperfect-box}}
%
\begin{proof}
\end{proof}

\subsubsection{Feature-Cardinality Constraints}
\label{sec:csd:appendix:proofs:alternatives}

\paragraph{Proof of Proposition~\ref{prop:csd:complexity-alternatives-perfect-box}}
%
\begin{proof}
\end{proof}

\paragraph{Proof of Proposition~\ref{prop:csd:complexity-alternatives-imperfect-box}}
%
\begin{proof}
\end{proof}

\renewcommand*{\bibfont}{\small} % use a smaller font for bib than for main text
\printbibliography

\end{document}
