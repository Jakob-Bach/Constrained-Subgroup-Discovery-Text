\documentclass{article}

\title{
	Constrained Subgroup Discovery
}
\author{
	Jakob Bach~\orcidlink{0000-0003-0301-2798}\\
	\small Karlsruhe Institute of Technology (KIT), Germany\\
	\small \href{mailto:jakob.bach@student.kit.edu}{jakob.bach@student.kit.edu}
}
\date{} % don't display a date

\usepackage[style=numeric, backend=bibtex]{biblatex}
\usepackage[ruled,linesnumbered,vlined]{algorithm2e} % pseudo-code
\usepackage{amsmath} % mathematical symbols
\usepackage{amssymb} % mathematical symbols
\usepackage{amsthm} % theorems, definitions etc.
\usepackage{booktabs} % nicely formatted tables (with top, mid, and bottom rule)
\usepackage{graphicx} % plots
\usepackage{multirow} % cells spanning multiple rows in tables
\usepackage{orcidlink} % ORCID icon
\usepackage{subcaption} % figures with multiple sub-figures and sub-captions
\usepackage{hyperref} % links and URLs

\addbibresource{references.bib}

\newtheorem{proposition}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}
%
\textbf{Keywords:} subgroup discovery, alternatives, constraints, satisfiability modulo theories, mixed-integer programming, explainability, interpretability, XAI

\section{Introduction}
\label{sec:csd:introduction}

\paragraph{Motivation}

\cite{carvalho2019machine} \cite{molnar2020interpretable}

\paragraph{Problem statement}

\paragraph{Related work}

\paragraph{Contributions}

\paragraph{Experimental results}

\paragraph{Outline}

Section~\ref{sec:csd:fundamentals} introduces notation and fundamentals.
Section~\ref{sec:csd:approach} describes and analyzes alternative feature selection.
Section~\ref{sec:csd:related-work} reviews related work.
Section~\ref{sec:csd:experimental-design} outlines our experimental design, while Section~\ref{sec:csd:evaluation} presents the experimental results.
Section~\ref{sec:csd:conclusion} concludes.
Appendix~\ref{sec:csd:appendix} contains supplementary materials.

\section{Fundamentals}
\label{sec:csd:fundamentals}

In this section, (cf.~Section~\ref{sec:csd:fundamentals:notation}) (cf.~Section~\ref{sec:csd:fundamentals:subgroup-discovery})

\cite{helal2016subgroup} \cite{herrera2011overview} \cite{atzmueller2015subgroup} \cite{ventura2018subgroup} \cite{meeng2021real}

To harmonize evaluation, we only consider binary-classification datasets, though subgroup discovery also works for regression problems.

\subsection{Notation}
\label{sec:csd:fundamentals:notation}

$X \in \mathbb{R}^{m \times n}$ stands for a dataset in the form of a matrix.
Each row is a data object, and each column is a feature.
$F = \{f_1, \dots, f_n\}$ is the corresponding set of feature names.
We assume that categorical features have already been made numeric, e.g., via one-hot or ordinal encoding.
$X_{\cdot{}j} \in \mathbb{R}^m$ denotes the vector representation of the $j$-th feature.
$y \in Y^m$ represents the prediction target with domain $Y$, e.g., $Y=\{0,1\}$ for binary classification or $Y=\mathbb{R}$ for regression.

In subgroup discovery, one ... (goal, decision variables)
The function $Q(...,X,y)$ returns the quality of such a subgroup.
Without loss of generality, we assume that this function should be maximized.

\subsection{Subgroup Discovery}
\label{sec:csd:fundamentals:subgroup-discovery}

In this section,

\paragraph{Problem}

\paragraph{PRIM}

\paragraph{Beam search}

\paragraph{BI}

\section{Constrained Subgroup Discovery}
\label{sec:csd:approach}

In this section, (cf.~Section~\ref{sec:csd:approach:smt}) (cf.~Section~\ref{sec:csd:approach:baselines}) (cf.~Section~\ref{sec:csd:approach:cardinality}) (cf.~Section~\ref{sec:csd:approach:alternatives})

\subsection{SMT}
\label{sec:csd:approach:smt}

Appendix~\ref{sec:csd:appendix:further-encodings} describes encodings of subgroup discovery with mixed-integer programming (MIP) and maximum satisfiability (MaxSAT).

\subsection{Baselines}
\label{sec:csd:approach:baselines}

\subsection{Feature-Cardinality Constraints}
\label{sec:csd:approach:cardinality}

In this section, In this section, (cf.~Section~\ref{sec:csd:approach:cardinality:concept}) (cf.~Section~\ref{sec:csd:approach:cardinality:smt}) (cf.~Section~\ref{sec:csd:approach:cardinality:heuristics}) (cf.~Section~\ref{sec:csd:approach:cardinality:baselines}) (cf.~Section~\ref{sec:csd:approach:cardinality:complexity})

\cite{mosek2022modeling}
\cite{sinz2005towards}
\cite{ulrich2022selecting}

\subsubsection{Concept}
\label{sec:csd:approach:cardinality:concept}

define term selected == restricted

\subsubsection{SMT Formulation}
\label{sec:csd:approach:cardinality:smt}

\subsubsection{Integration into Heuristic Search}
\label{sec:csd:approach:cardinality:heuristics}

\subsubsection{Integration into Baselines}
\label{sec:csd:approach:cardinality:baselines}

\subsubsection{Computational Complexity}
\label{sec:csd:approach:cardinality:complexity}

\subsection{Alternative Subgroup Descriptions}
\label{sec:csd:approach:alternatives}

In this section, (cf.~Section~\ref{sec:csd:approach:alternatives:concept}) (cf.~Section~\ref{sec:csd:approach:alternatives:smt}) (cf.~Section~\ref{sec:csd:approach:alternatives:heuristics}) (cf.~Section~\ref{sec:csd:approach:alternatives:complexity})

\subsubsection{Concept}
\label{sec:csd:approach:alternatives:concept}

$\tau_{\text{abs}}$
The subscript \emph{abs} denotes that the dissimilarity threshold refers to an absolute number of features, i.e., the threshold is not normalized to $[0,1]$.

\subsubsection{SMT Formulation}
\label{sec:csd:approach:alternatives:smt}

\subsubsection{Integration into Heuristic Search}
\label{sec:csd:approach:alternatives:heuristics}

Beam only, no baselines.

\subsubsection{Computational Complexity}
\label{sec:csd:approach:alternatives:complexity}

\section{Related Work}
\label{sec:csd:related-work}

In this section, (cf.~Section~\ref{sec:csd:related-work:subgroup-discovery}) (cf.~Section~\ref{sec:csd:related-work:feature-selection})
(cf.~Section~\ref{sec:csd:related-work:other})

\subsection{Subgroup Discovery}
\label{sec:csd:related-work:subgroup-discovery}

PRIM~\cite{friedman1999bump}, BI~\cite{mampaey2012efficient}
depth-first~\cite{millot2020optimal}
exhaustive~\cite{atzmueller2006sd, atzmueller2009fast, grosskreutz2009subgroup, lemmerich2016fast}
exhaustive with diversity~\cite{bosc2018anytime, lemmerich2010fast}
heuristics with diversity \cite{leeuwen2012diverse, lucas2018ssdp+, proencca2022robust}
analyze Pareto front for diversity (exact and greedy) \cite{leeuwen2013discovering}
diverse subgroup lists \cite{lopez2023discovering, lopez2023novel}
diverse rule sets \cite{zhang2020diverse}
heuristic with constraints \cite{lavravc2006relevancy}
contrasting SD \cite{langohr2013contrasting}
involve domain experts/knowledge \cite{dzyuba2013interactive, gamberger2002expert, lemmerich2011local}
background knowledge \cite{atzmueller2005exploiting, atzmueller2006methodological}
`propositionalization to describe subgroups' \cite{zelezny2006propositionalization}

from chair: \cite{arzamasov2021reds} \cite{arzamasov2022pedagogical} \cite{vollmer2019informative}

minimizing subgroups NP-hard~\cite{boley2009non}

measures of subgroup complexity \cite{helal2016subgroup, herrera2011overview, ventura2018subgroup} -> num subgroups and num selected features

\subsection{Feature Selection}
\label{sec:csd:related-work:feature-selection}

\cite{bach2022empirical} \cite{bach2023finding}

\subsection{Other Fields}
\label{sec:csd:related-work:other}

\cite{bailey2014alternative} \cite{grossi2017survey}
\cite{guidotti2022counterfactual}
\cite{narodytska2018learning} \cite{schidler2021sat} \cite{yu2021learning}

\section{Experimental Design}
\label{sec:csd:experimental-design}

In this section, we introduce our experimental design.
After a brief overview of its components (cf.~Section~\ref{sec:csd:experimental-design:overview}), we describe evaluation metrics (cf.~Section~\ref{sec:csd:experimental-design:metrics}), methods (cf.~Section~\ref{sec:csd:experimental-design:methods}), and datasets (cf.~Section~\ref{sec:csd:experimental-design:datasets}).
Finally, we shortly outline our implementation (cf.~Section~\ref{sec:csd:experimental-design:implementation}).

\subsection{Overview}
\label{sec:csd:experimental-design:overview}

In our experiments, we evaluate six subgroup-discovery methods on 27 binary-classification datasets.
We measure the subgroup quality in terms of Weighted Relative Accuracy (WRAcc) and also record the runtime of the methods.
We compare all subgroup-discovery methods without constraints as well as with a constraint on the number of selected features~$k$, varying the latter parameter.
For solver-based optimization, we additionally vary the solver timeout.
Finally, we search for alternative subgroup descriptions with one solver-based and one heuristic search method.
We vary the number of alternatives~$a$ and the dissimilarity threshold~$\tau_{\text{abs}}$.

\subsection{Evaluation Metrics}
\label{sec:csd:experimental-design:metrics}

\paragraph{Quality}

\paragraph{Similarity}

\paragraph{Runtime}

\subsection{Methods}
\label{sec:csd:experimental-design:methods}

(cf.~Section~\ref{sec:csd:experimental-design:methods:subgroup-discovery}) (cf.~Section~\ref{sec:csd:experimental-design:methods:cardinality}) (cf.~Section~\ref{sec:csd:experimental-design:methods:alternatives})

\subsubsection{Subgroup Discovery}
\label{sec:csd:experimental-design:methods:subgroup-discovery}

according to Vadim's Medium blog post, REDS article should say that pasting phase of PRIM has little effect on quality

\cite{lemmerich2019pysubgroup}
\cite{arzamasov2021reds}

\paragraph{Heuristic search}

Section~\ref{sec:csd:fundamentals:subgroup-discovery}

\paragraph{Baselines}

Section~\ref{sec:csd:approach:baselines}

\paragraph{Solver-based search}

Section~\ref{sec:csd:approach:smt}

\paragraph{Timeouts}

Section~\ref{sec:csd:evaluation:timeouts}

\subsubsection{Feature-Cardinality Constraints}
\label{sec:csd:experimental-design:methods:cardinality}

Section~\ref{sec:csd:approach:cardinality}
Section~\ref{sec:csd:evaluation:cardinality}

\subsubsection{Alternative Subgroup Descriptions}
\label{sec:csd:experimental-design:methods:alternatives}

Section~\ref{sec:csd:approach:alternatives}
Section~\ref{sec:csd:evaluation:alternatives}

\begin{table}[p]
	\centering
	\begin{tabular}{lrrll}
		\toprule
		\multirow{2}{*}{Dataset} & \multirow{2}{*}{$m$} & \multirow{2}{*}{$n$} & \multicolumn{2}{c}{Timeouts} \\
		\cmidrule(lr){4-5}
		& & & Max~$k$ & Any~$k$ \\
		\midrule
		backache & 180 & 32 & No & No \\
		chess & 3196 & 36 & No & No \\
		churn & 5000 & 20 & Yes & Yes \\
		clean1 & 476 & 168 & No & No \\
		clean2 & 6598 & 168 & No & No \\
		coil2000 & 9822 & 85 & Yes & Yes \\
		credit\_g & 1000 & 20 & Yes & Yes \\
		dis & 3772 & 29 & No & No \\
		GE\_2\_Way\_20atts\_0.1H\_EDM\_1\_1 & 1600 & 20 & Yes & Yes \\
		GE\_2\_Way\_20atts\_0.4H\_EDM\_1\_1 & 1600 & 20 & No & No \\
		GE\_3\_Way\_20atts\_0.2H\_EDM\_1\_1 & 1600 & 20 & Yes & Yes \\
		GH\_20atts\_1600\_Het\_0.4\_0.2\_50\_EDM\_2\_001 & 1600 & 20 & Yes & Yes \\
		GH\_20atts\_1600\_Het\_0.4\_0.2\_75\_EDM\_2\_001 & 1600 & 20 & Yes & Yes \\
		Hill\_Valley\_with\_noise & 1212 & 100 & Yes & Yes \\
		horse\_colic & 368 & 22 & No & No \\
		hypothyroid & 3163 & 25 & No & No \\
		ionosphere & 351 & 34 & Yes & Yes \\
		molecular\_biology\_promoters & 106 & 57 & No & No \\
		mushroom & 8124 & 22 & No & No \\
		ring & 7400 & 20 & Yes & Yes \\
		sonar & 208 & 60 & No & Yes \\
		spambase & 4601 & 57 & No & Yes \\
		spect & 267 & 22 & No & No \\
		spectf & 349 & 44 & No & Yes \\
		tokyo1 & 959 & 44 & No & Yes \\
		twonorm & 7400 & 20 & Yes & Yes \\
		wdbc & 569 & 30 & No & No \\
		\bottomrule
	\end{tabular}
	\caption{
		Datasets from PMLB used in our experiments.
		$m$~denotes the number of data objects and $n$~the number of features.
		In dataset names, we replaced \emph{GAMETES\_Epistasis} with  \emph{GE\_} and \emph{GAMETES\_Heterogeneity} with \emph{GH\_} to reduce the table's width.
		The column \emph{Timeouts} indicates whether at least one timeout occurred with \emph{SMT} as the subgroup-discovery method and the highest timeout (2048~s), optimizing the original subgroup without cardinality constraints (\emph{Max~$k$}) or in any cardinality setting (\emph{Any~$k$}).
	}
	\label{tab:afs:datasets}
\end{table}

\subsection{Datasets}
\label{sec:csd:experimental-design:datasets}

We use binary-classification datasets from the Penn Machine Learning Benchmarks (PMLB)~\cite{olson2017pmlb, romano2021pmlb}.
If both classes occur with different frequencies, we encode the minority class as the class of interest, i.e., assign~1 as it class label.
To avoid prediction scenarios that may be too easy or have not enough features for alternative subgroup descriptions, we only select datasets with at least 100 data objects and 20 features.
Next, we exclude one dataset with 1000 features, which has a significantly higher dimensionality than all remaining datasets.
Finally, we manually exclude datasets that seem duplicated or modified versions of other datasets in our experiments.

Based on these criteria, we obtain 27 datasets with 106 to 9822 data objects and 20 to 168 features (cf.~Table~\ref{tab:afs:datasets}).
The datasets do not contain any missing values.
Further, there are no categorical feature values since PMLB encodes them ordinally by default.

\subsection{Implementation and Execution}
\label{sec:csd:experimental-design:implementation}

We implemented all subgroup-discovery methods, experiments, and evaluations in Python~3.8.
A requirements file in our repository specifies the versions of all Python packages.
The solver \emph{Z3}~\cite{bjorner2015nuz, deMoura2008z3} carries out the SMT optimization.
The experimental pipeline parallelizes over datasets, cross-validation folds, and subgroup-discovery methods, while each of these experimental tasks runs single-threaded.
We ran the pipeline on a server with 128~GB RAM and an \emph{AMD EPYC 7551} CPU, having 32~physical cores and a base clock of 2.0~GHz.
With this hardware, the parallelized pipeline run took approximately 39~hours.

\section{Evaluation}
\label{sec:csd:evaluation}

In this section, (cf.~Section~\ref{sec:csd:evaluation:unconstrained}) (cf.~Section~\ref{sec:csd:evaluation:timeouts}) (cf.~Section~\ref{sec:csd:evaluation:cardinality}) (cf.~Section~\ref{sec:csd:evaluation:alternatives}) (cf.~Section~\ref{sec:csd:evaluation:summary})

\subsection{Unconstrained Subgroup Discovery}
\label{sec:csd:evaluation:unconstrained}

\paragraph{Training-set quality}

\paragraph{Test-set quality}

\paragraph{Overfitting}

\paragraph{Runtime}

\subsection{Solver Timeouts}
\label{sec:csd:evaluation:timeouts}

\subsection{Feature-Cardinality Constraints}
\label{sec:csd:evaluation:cardinality}

\paragraph{Quality}

\paragraph{Runtime}

\subsection{Alternative Subgroup Descriptions}
\label{sec:csd:evaluation:alternatives}

\paragraph{Quality}

\paragraph{Runtime}

\subsection{Summary}
\label{sec:csd:evaluation:summary}

\paragraph{Unconstrained subgroup discovery (cf.~Section~\ref{sec:csd:evaluation:unconstrained})}

\paragraph{Solver timeouts (cf.~Section~\ref{sec:csd:evaluation:timeouts})}

\paragraph{Feature-cardinality constraints (cf.~Section~\ref{sec:csd:evaluation:cardinality})}

\paragraph{Alternative subgroup descriptions (cf.~Section~\ref{sec:csd:evaluation:alternatives})}

\section{Conclusions and Future Work}
\label{sec:csd:conclusion}

In this section, we recap our article (cf.~Section~\ref{sec:csd:conclusion:conclusion}) and propose directions for future work (cf.~Section~\ref{sec:csd:conclusion:future-work}).

\subsection{Conclusions}
\label{sec:csd:conclusion:conclusion}

\subsection{Future Work}
\label{sec:csd:conclusion:future-work}

%~\\
%\noindent \textsc{Acknowledgments}\quad
%This work was supported by the Ministry of Science, Research and the Arts Baden-Württemberg, project \emph{Algorithm Engineering for the Scalability Challenge (AESC)}.

\appendix

\section{Appendix}
\label{sec:csd:appendix}

In this section, we provide supplementary materials.
Appendix~\ref{sec:csd:appendix:further-encodings} describes further encodings of the subgroup-discovery problem, complementing the SMT formulation from Section~\ref{sec:csd:approach:smt}.

\subsection{Further Problem Encodings of Subgroup Discovery}
\label{sec:csd:appendix:further-encodings}

\paragraph{MIP}

Our published code contains a MIP implementation with the package \emph{OR-Tools}~\cite{perron2022or-tools}, using \emph{SCIP}~\cite{bestuzheva2021scip} as the optimizer.
However, this formulation was (on average) slower than the SMT formulation in preliminary experiments, so we stuck to the latter for our main experiments (cf.~Section~\ref{sec:csd:experimental-design:methods:subgroup-discovery}).

\paragraph{MaxSAT}

\cite{li2021maxsat} \cite{bacchus2021maximum}

\renewcommand*{\bibfont}{\small} % use a smaller font for bib than for main text
\printbibliography

\end{document}
