\documentclass{article}

\title{
	Constrained Subgroup Discovery
}
\author{
	Jakob Bach~\orcidlink{0000-0003-0301-2798}\\
	\small Karlsruhe Institute of Technology (KIT), Germany\\
	\small \href{mailto:jakob.bach@student.kit.edu}{jakob.bach@student.kit.edu}
}
\date{} % don't display a date

\usepackage[style=numeric, backend=bibtex]{biblatex}
\usepackage[ruled,linesnumbered,vlined]{algorithm2e} % pseudo-code
\usepackage{amsmath} % mathematical symbols
\usepackage{amssymb} % mathematical symbols
\usepackage{amsthm} % theorems, definitions etc.
\usepackage{booktabs} % nicely formatted tables (with top, mid, and bottom rule)
\usepackage{graphicx} % plots
\usepackage{multirow} % cells spanning multiple rows in tables
\usepackage{orcidlink} % ORCID icon
\usepackage{subcaption} % figures with multiple sub-figures and sub-captions
\usepackage{hyperref} % links and URLs

\addbibresource{references.bib}

\newtheorem{proposition}{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}
%
\textbf{Keywords:} subgroup discovery, alternatives, constraints, satisfiability modulo theories, mixed-integer programming, explainability, interpretability, XAI

\section{Introduction}
\label{sec:osd:introduction}

\paragraph{Motivation}

\cite{carvalho2019machine} \cite{molnar2020interpretable}

\paragraph{Problem statement}

\paragraph{Related work}

\paragraph{Contributions}

\paragraph{Experimental results}

\paragraph{Outline}

Section~\ref{sec:osd:fundamentals} introduces notation and fundamentals.
Section~\ref{sec:osd:approach} describes and analyzes alternative feature selection.
Section~\ref{sec:osd:related-work} reviews related work.
Section~\ref{sec:osd:experimental-design} outlines our experimental design, while Section~\ref{sec:osd:evaluation} presents the experimental results.
Section~\ref{sec:osd:conclusion} concludes.
Appendix~\ref{sec:osd:appendix} contains supplementary materials.

\section{Fundamentals}
\label{sec:osd:fundamentals}

\cite{helal2016subgroup} \cite{herrera2011overview} \cite{atzmueller2015subgroup} \cite{ventura2018subgroup} \cite{meeng2021real}

\subsection{Notation}
\label{sec:osd:fundamentals:notation}

$X \in \mathbb{R}^{m \times n}$ stands for a dataset in the form of a matrix.
Each row is a data object, and each column is a feature.
$F = \{f_1, \dots, f_n\}$ is the corresponding set of feature names.
We assume that categorical features have already been made numeric, e.g., via one-hot or ordinal encoding.
$X_{\cdot{}j} \in \mathbb{R}^m$ denotes the vector representation of the $j$-th feature.
$y \in Y^m$ represents the prediction target with domain $Y$, e.g., $Y=\{0,1\}$ for binary classification or $Y=\mathbb{R}$ for regression.

In subgroup discovery, one ... (goal, decision variables)
The function $Q(...,X,y)$ returns the quality of such a subgroup.
Without loss of generality, we assume that this function should be maximized.

\section{Approach}
\label{sec:osd:approach}

\subsection{Optimization Problem}
\label{sec:osd:approach:problem}

MaxSAT: \cite{li2021maxsat} \cite{bacchus2021maximum}
SMT: \cite{barrett2018satisfiability}

\subsection{Constraints}
\label{sec:osd:approach:constraints}

\cite{mosek2022modeling}
\cite{sinz2005towards}
\cite{ulrich2022selecting}

\subsection{Objective Functions}
\label{sec:osd:approach:objectives}

\subsection{Computational Complexity}
\label{sec:osd:approach:complexity}

\section{Related Work}
\label{sec:osd:related-work}

\subsection{Subgroup Discovery}
\label{sec:osd:related-work:subgroup-discovery}

PRIM~\cite{friedman1999bump}, BI~\cite{mampaey2012efficient}
depth-first~\cite{millot2020optimal}
exhaustive~\cite{atzmueller2006sd, atzmueller2009fast, grosskreutz2009subgroup, lemmerich2016fast}
exhaustive with diversity~\cite{bosc2018anytime, lemmerich2010fast}
heuristics with diversity \cite{leeuwen2012diverse, lucas2018ssdp+, proencca2022robust}
analyze Pareto front for diversity (exact and greedy) \cite{leeuwen2013discovering}
diverse subgroup lists \cite{lopez2023discovering, lopez2023novel}
diverse rule sets \cite{zhang2020diverse}
heuristic with constraints \cite{lavravc2006relevancy}
contrasting SD \cite{langohr2013contrasting}
involve domain experts/knowledge \cite{dzyuba2013interactive, gamberger2002expert, lemmerich2011local}
background knowledge \cite{atzmueller2005exploiting, atzmueller2006methodological}
`propositionalization to describe subgroups' \cite{zelezny2006propositionalization}

from chair: \cite{arzamasov2021reds} \cite{arzamasov2022pedagogical} \cite{vollmer2019informative}

minimizing subgroups NP-hard~\cite{boley2009non}

measures of subgroup complexity \cite{helal2016subgroup, herrera2011overview, ventura2018subgroup} -> num subgroups and num selected features

\subsection{Feature Selection}
\label{sec:osd:related-work:feature-selection}

\cite{bach2022empirical} \cite{bach2023finding}

\subsection{Other Fields}
\label{sec:osd:related-work:other}

\cite{bailey2014alternative} \cite{grossi2017survey}
\cite{guidotti2022counterfactual}
\cite{narodytska2018learning} \cite{schidler2021sat} \cite{yu2021learning}

\section{Experimental Design}
\label{sec:osd:experimental-design}

\subsection{Overview}
\label{sec:osd:experimental-design:overview}

\subsection{Evaluation Metrics}
\label{sec:osd:experimental-design:evaluation}

\paragraph{Quality}

\paragraph{Runtime}

\subsection{Methods}
\label{sec:osd:experimental-design:methods}

according to Vadim's Medium blog post, REDS article should say that pasting phase of PRIM has little effect on quality

\begin{table}[p]
	\centering
	\begin{tabular}{lrrll}
		\toprule
		\multirow{2}{*}{Dataset} & \multirow{2}{*}{$m$} & \multirow{2}{*}{$n$} & \multicolumn{2}{c}{Timeouts} \\
		\cmidrule(lr){4-5}
		& & & Max~$k$ & Any~$k$ \\
		\midrule
		backache & 180 & 32 & No & No \\
		chess & 3196 & 36 & No & No \\
		churn & 5000 & 20 & Yes & Yes \\
		clean1 & 476 & 168 & No & No \\
		clean2 & 6598 & 168 & No & No \\
		coil2000 & 9822 & 85 & Yes & Yes \\
		credit\_g & 1000 & 20 & Yes & Yes \\
		dis & 3772 & 29 & No & No \\
		GE\_2\_Way\_20atts\_0.1H\_EDM\_1\_1 & 1600 & 20 & Yes & Yes \\
		GE\_2\_Way\_20atts\_0.4H\_EDM\_1\_1 & 1600 & 20 & No & No \\
		GE\_3\_Way\_20atts\_0.2H\_EDM\_1\_1 & 1600 & 20 & Yes & Yes \\
		GH\_20atts\_1600\_Het\_0.4\_0.2\_50\_EDM\_2\_001 & 1600 & 20 & Yes & Yes \\
		GH\_20atts\_1600\_Het\_0.4\_0.2\_75\_EDM\_2\_001 & 1600 & 20 & Yes & Yes \\
		Hill\_Valley\_with\_noise & 1212 & 100 & Yes & Yes \\
		horse\_colic & 368 & 22 & No & No \\
		hypothyroid & 3163 & 25 & No & No \\
		ionosphere & 351 & 34 & Yes & Yes \\
		molecular\_biology\_promoters & 106 & 57 & No & No \\
		mushroom & 8124 & 22 & No & No \\
		ring & 7400 & 20 & Yes & Yes \\
		sonar & 208 & 60 & No & Yes \\
		spambase & 4601 & 57 & No & Yes \\
		spect & 267 & 22 & No & No \\
		spectf & 349 & 44 & No & Yes \\
		tokyo1 & 959 & 44 & No & Yes \\
		twonorm & 7400 & 20 & Yes & Yes \\
		wdbc & 569 & 30 & No & No \\
		\bottomrule
	\end{tabular}
	\caption{
		Datasets from PMLB used in our experiments.
		$m$~denotes the number of data objects and $n$~the number of features.
		In dataset names, we replaced \emph{GAMETES\_Epistasis} with  \emph{GE\_} and \emph{GAMETES\_Heterogeneity} with \emph{GH\_} to reduce the table's width.
		The column \emph{Timeouts} indicates whether at least one timeout occurred with \emph{SMT} as the subgroup-discovery method and the highest timeout (2048~s), optimizing the original subgroup without cardinality constraints (\emph{Max~$k$}) or in any cardinality setting (\emph{Any~$k$}).
	}
	\label{tab:afs:datasets}
\end{table}

\subsection{Datasets}
\label{sec:osd:experimental-design:datasets}

We use binary-classification datasets from the Penn Machine Learning Benchmarks (PMLB)~\cite{olson2017pmlb, romano2021pmlb}.
If both classes occur with different frequencies, we encode the minority class as the class of interest, i.e., assign~1 as it class label.
To avoid prediction scenarios that may be too easy or have not enough features for alternative subgroup descriptions, we only select datasets with at least 100 data objects and 20 features.
Next, we exclude one dataset with 1000 features, which has a significantly higher dimensionality than all remaining datasets.
Finally, we manually exclude datasets that seem duplicated or modified versions of other datasets in our experiments.

Based on these criteria, we obtain 27 datasets with 106 to 9822 data objects and 20 to 168 features (cf.~Table~\ref{tab:afs:datasets}).
The datasets do not contain any missing values.
Further, there are no categorical feature values since PMLB encodes them ordinally by default.

\subsection{Implementation and Execution}
\label{sec:osd:experimental-design:implementation}

\cite{bestuzheva2021scip}
\cite{deMoura2008z3}
\cite{bjorner2015nuz}
\cite{perron2022or-tools}
\cite{lemmerich2019pysubgroup}

\section{Evaluation}
\label{sec:osd:evaluation}

\subsection{Summary}
\label{sec:osd:evaluation:summary}

\section{Conclusions and Future Work}
\label{sec:osd:conclusion}

\subsection{Conclusions}
\label{sec:osd:conclusion:conclusion}

\subsection{Future Work}
\label{sec:osd:conclusion:future-work}

%~\\
%\noindent \textsc{Acknowledgments}\quad
%This work was supported by the Ministry of Science, Research and the Arts Baden-WÃ¼rttemberg, project \emph{Algorithm Engineering for the Scalability Challenge (AESC)}.

\appendix

\section{Appendix}
\label{sec:osd:appendix}

In this section, we provide supplementary materials.

MIP?
MaxSAT?

\renewcommand*{\bibfont}{\small} % use a smaller font for bib than for main text
\printbibliography

\end{document}
